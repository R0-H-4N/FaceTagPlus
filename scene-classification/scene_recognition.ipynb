{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a1a5a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sapha\\OneDrive\\Desktop\\FuseProject\\CLIP\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import open_clip\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64f63749",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c19fd78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sapha\\OneDrive\\Desktop\\FuseProject\\CLIP\\.venv\\lib\\site-packages\\open_clip\\factory.py:450: UserWarning: QuickGELU mismatch between final model config (quick_gelu=False) and pretrained tag 'openai' (quick_gelu=True).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Load model, tokenizer, and preprocessing\n",
    "model_name = \"ViT-B-32\"          # ViT-L-14, ViT-B-16, etc.\n",
    "pretrained_dataset = \"openai\"    #\"openai\", \"laion400m_e32\", \"laion2b_s34b_b79k\"\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    model_name, pretrained=pretrained_dataset\n",
    ")\n",
    "tokenizer = open_clip.get_tokenizer(model_name)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b1e0685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test image\n",
    "image_path = \"clip_test2.jpg\"  # replace with your own file\n",
    "image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14ce9376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scene descriptions\n",
    "scene_prompts = [\n",
    "    \"beach\",\n",
    "    \"forest\",\n",
    "    \"mountain\",\n",
    "    \"office\",\n",
    "    \"classroom\",\n",
    "    \"street\",\n",
    "    \"cafeteria\",\n",
    "    \"kitchen\",\n",
    "    \"living room\",\n",
    "    \"wedding\",\n",
    "    \"concert\",\n",
    "    \"sports event\",\n",
    "    \"park\",\n",
    "    \"desert\",\n",
    "    \"cityscape\",\n",
    "]\n",
    "\n",
    "# Tokenize the text\n",
    "text = tokenizer(scene_prompts).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da0c04f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "\n",
    "    # Normalize\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Similarity scores\n",
    "    similarity = (100.0 * image_features @ text_features.T)\n",
    "    probs = similarity.softmax(dim=-1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eecd8c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beach                          -> 0.10%\n",
      "forest                         -> 1.37%\n",
      "mountain                       -> 93.03%\n",
      "office                         -> 0.90%\n",
      "classroom                      -> 0.49%\n",
      "street                         -> 0.18%\n",
      "cafeteria                      -> 0.09%\n",
      "kitchen                        -> 0.10%\n",
      "living room                    -> 0.22%\n",
      "wedding                        -> 0.07%\n",
      "concert                        -> 0.13%\n",
      "sports event                   -> 1.62%\n",
      "park                           -> 0.80%\n",
      "desert                         -> 0.78%\n",
      "cityscape                      -> 0.12%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "for i, scene in enumerate(scene_prompts):\n",
    "    print(f\"{scene:30s} -> {probs[0][i]*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb115a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 5 Scene Predictions:\n",
      "mountain                       -> 93.03%\n",
      "sports event                   -> 1.62%\n",
      "forest                         -> 1.37%\n",
      "office                         -> 0.90%\n",
      "park                           -> 0.80%\n"
     ]
    }
   ],
   "source": [
    "# Only get top 5 results\n",
    "top_probs, top_labels = torch.topk(torch.tensor(probs), 5)\n",
    "print(\"\\nTop 5 Scene Predictions:\")\n",
    "for i in range(top_probs.shape[1]):\n",
    "    print(f\"{scene_prompts[top_labels[0][i]]:30s} -> {top_probs[0][i]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7179659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mountain                       -> 93.03%\n"
     ]
    }
   ],
   "source": [
    "# Top 1 prediction\n",
    "top1_idx = np.argmax(probs)\n",
    "print(f\"{scene_prompts[top1_idx]:30s} -> {probs[0][top1_idx]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3624c9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mountain                       -> 93.03%\n"
     ]
    }
   ],
   "source": [
    "# Only output if the top prediction is above a certain threshold\n",
    "threshold = 0.4  # 40%\n",
    "if probs[0][top1_idx] > threshold:\n",
    "    print(f\"{scene_prompts[top1_idx]:30s} -> {probs[0][top1_idx]*100:.2f}%\")\n",
    "else:\n",
    "    print(\"Unsure but top prediction is: \"+f\"{scene_prompts[top1_idx]:30s} -> {probs[0][top1_idx]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df233858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction of batch of images in a folder\n",
    "import os\n",
    "\n",
    "image_folder = os.path.join(os.getcwd(), \"images\") \n",
    "image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825ce2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

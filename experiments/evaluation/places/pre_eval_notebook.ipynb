{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7cf0ee28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_name': 'resnet50', 'batch_size': 32, 'num_epochs': 30, 'learning_rate': 0.001, 'weight_decay': 0.0005, 'dropout_rate': 0.5, 'save_dir': './finetuned_models', 'data_dir': './train', 'device': 'cuda', 'gradual_unfreeze': True, 'unfreeze_schedule': [[1, 'classifier', 1.0], [4, 'layer4', 0.1], [7, 'layer3', 0.05], [10, 'layer2', 0.01], [13, 'all', 0.005]], 'overfit_early_stop': True, 'overfit_threshold': 10.0, 'overfit_val_acc_threshold': 80.0, 'overfit_patience': 3, 'early_stopping': True, 'early_stopping_patience': 7, 'early_stopping_min_delta': 0.001}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import json\n",
    "import os\n",
    "with open(\"./models_places365/categories_places365.txt\") as f:\n",
    "    categories = [line.strip().split()[0].split('/')[-1] for line in f]\n",
    "cat_2_idx = {cat : i for i, cat in enumerate(categories)}\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "with open('./finetuned_models/resnet50_20251209_111405/config.json') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "270bc2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Model Loading Functions\n",
    "# ============================================================================\n",
    "\n",
    "def load_finetuned_model(checkpoint_path, device='cuda'):\n",
    "    \"\"\"\n",
    "    Load a fine-tuned model from checkpoint\n",
    "    \n",
    "    Args:\n",
    "        checkpoint_path: Path to the .pth checkpoint file\n",
    "        device: 'cuda' or 'cpu'\n",
    "    \n",
    "    Returns:\n",
    "        model: Loaded model in eval mode\n",
    "        checkpoint: Full checkpoint dict (contains config, class mappings, etc.)\n",
    "\n",
    "    \"\"\"\n",
    "    # Load checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)\n",
    "    \n",
    "    # Get config\n",
    "    config = checkpoint['config']\n",
    "    model_name = config['model_name']\n",
    "    dropout_rate = config.get('dropout_rate', 0.5)\n",
    "    \n",
    "    # Create model architecture\n",
    "    if model_name == 'resnet18':\n",
    "        model = models.resnet18(weights=None)\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 365)  # 365 Places365 classes\n",
    "        )\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(weights=None)\n",
    "        model.fc = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(2048, 365)\n",
    "        )\n",
    "    elif model_name == 'densenet':\n",
    "        model = models.densenet161(weights=None)\n",
    "        model.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(2208, 365)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model: {model_name}\")\n",
    "    \n",
    "    # Load weights\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    print(f\"âœ“ Loaded {model_name} from epoch {checkpoint['epoch']}\")\n",
    "    print(f\"  Val Accuracy: {checkpoint['val_acc']:.2f}%\")\n",
    "    print(f\"  Val Loss: {checkpoint['val_loss']:.4f}\")\n",
    "    \n",
    "    return model, checkpoint\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Image Preprocessing\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Inference Functions\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# Example Usage\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def loadModel(model_name, num_classes=365):\n",
    "    if model_name == 'resnet18':\n",
    "        model = models.resnet18(weights=None)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        model_path = \"./models_places365/resnet18_places365.pth.tar\"\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(weights=None)\n",
    "        model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        model_path = \"./models_places365/resnet50_places365.pth.tar\"\n",
    "    elif model_name == 'densenet':\n",
    "        model = models.densenet161(weights=None)\n",
    "        num_features = model.classifier.in_features\n",
    "        model.classifier = nn.Linear(num_features, num_classes)\n",
    "        model_path = \"./models_places365/densenet161_places365.pth.tar\"\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown model name: {model_name}\")\n",
    "\n",
    "    checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)\n",
    "    # Possible keys for different training formats\n",
    "    if 'state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['state_dict']\n",
    "    elif 'model_state_dict' in checkpoint:\n",
    "        state_dict = checkpoint['model_state_dict']\n",
    "    else:\n",
    "        state_dict = checkpoint  # raw state_dict\n",
    "\n",
    "\n",
    "    # Remove 'module.' prefix if present (from DataParallel)\n",
    "    new_state_dict = {}\n",
    "    for k, v in state_dict.items():\n",
    "        name = k.replace('module.', '')\n",
    "        \n",
    "        # Fix DenseNet naming: convert 'norm.1' -> 'norm1', 'conv.2' -> 'conv2', etc.\n",
    "        # This handles the old checkpoint format vs new torchvision format\n",
    "        if model_name == 'densenet':\n",
    "            name = re.sub(r'\\.(\\d+)\\.', lambda m: m.group(1) + '.', name)\n",
    "        \n",
    "        new_state_dict[name] = v\n",
    "\n",
    "    # Load weights\n",
    "    try:\n",
    "        model.load_state_dict(new_state_dict, strict=True)\n",
    "        print(f\"Successfully loaded {model_name} weights\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"Warning: Could not load with strict=True, trying strict=False\")\n",
    "        print(f\"Error: {e}\")\n",
    "        model.load_state_dict(new_state_dict, strict=False)\n",
    "    \n",
    "    model.eval()\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb456af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fc9d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "img_transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47322c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Places(Dataset):\n",
    "    def __init__(self, img_transform):\n",
    "        self.labels = []\n",
    "        self.img_transform = img_transform\n",
    "        with open('./val_256/places365_val.txt', 'r') as f:\n",
    "            self.labels = [int(line.strip().split()[-1]) for line in f]\n",
    "        with open('./val_256/places365_val.txt', 'r') as f:\n",
    "            self.img_paths = [('./val_256/' + str(line.strip().split()[0])) for line in f]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.img_paths[index]).convert('RGB')\n",
    "        img_tensor = self.img_transform(image)\n",
    "        return img_tensor, torch.tensor(self.labels[index], dtype=torch.long)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "829f97b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "places365_val_dataset = Places(img_transform)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2eb1b27c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x =  torch.randn([4, 4])\n",
    "i, p = torch.topk(x, k=2)\n",
    "p[0][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f6e542a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_dataset = datasets.ImageFolder(\n",
    "    root='./train',\n",
    "    transform=img_transform\n",
    ")\n",
    "new_map = {cls_name: cat_2_idx[cls_name] for cls_name in custom_dataset.classes}\n",
    "\n",
    "custom_dataset.class_to_idx = new_map\n",
    "custom_dataset.samples = [\n",
    "    (path, new_map[class_name])\n",
    "    for (path, _old_idx) in custom_dataset.samples\n",
    "    for class_name in [path.split(os.sep)[-2]]\n",
    "]\n",
    "\n",
    "custom_dataset.targets = [label for _, label in custom_dataset.samples]\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc858e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "places_loader = DataLoader(places365_val_dataset, batch_size=32, shuffle=True)\n",
    "custom_loader = DataLoader(custom_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3714049a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchmetrics import Accuracy, Precision, Recall, F1Score\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def evaluate_with_thresholds(model, dataloader, num_classes, thresholds=[i/10 for i in range(10)], device='cuda', custome_targets=None):\n",
    "    \"\"\"\n",
    "    Evaluate precision/recall/f1 at different confidence thresholds\n",
    "    \"\"\"\n",
    "    if custome_targets is None:\n",
    "        custome_targets = [i for i in range(num_classes)]\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    # Collect all predictions first\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\"Collecting predictions...\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            images = images.to(device)\n",
    "            logits = model(images)\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            \n",
    "            all_probs.append(probs[:, custome_targets].cpu())\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    all_probs = torch.cat(all_probs, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "\n",
    "    \n",
    "    # Get top-1 predictions and confidences\n",
    "    confidences, predictions = torch.max(all_probs, dim=1)\n",
    "    \n",
    "    results = []\n",
    "    print(\"\\nComputing metrics for each threshold...\")\n",
    "    for threshold in tqdm(thresholds, desc=\"Thresholds\"):\n",
    "        # Filter by threshold\n",
    "        mask = confidences >= threshold\n",
    "        \n",
    "        if mask.sum() == 0:\n",
    "            print(f\"Warning: No predictions above threshold {threshold}\")\n",
    "            continue\n",
    "        \n",
    "        filtered_preds = predictions[mask]\n",
    "        filtered_labels = all_labels[mask]\n",
    "        \n",
    "        # Compute metrics on filtered predictions\n",
    "        acc_metric = Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "        \n",
    "        prec_macro = Precision(task=\"multiclass\", num_classes=num_classes, average=\"macro\")\n",
    "        prec_micro = Precision(task=\"multiclass\", num_classes=num_classes, average=\"micro\")\n",
    "        \n",
    "        recall_macro = Recall(task=\"multiclass\", num_classes=num_classes, average=\"macro\")\n",
    "        recall_micro = Recall(task=\"multiclass\", num_classes=num_classes, average=\"micro\")\n",
    "        \n",
    "        f1_macro = F1Score(task=\"multiclass\", num_classes=num_classes, average=\"macro\")\n",
    "        f1_micro = F1Score(task=\"multiclass\", num_classes=num_classes, average=\"micro\")\n",
    "        \n",
    "        accuracy = acc_metric(filtered_preds, filtered_labels).item()\n",
    "        precision_macro = prec_macro(filtered_preds, filtered_labels).item()\n",
    "        precision_micro = prec_micro(filtered_preds, filtered_labels).item()\n",
    "        recall_macro = recall_macro(filtered_preds, filtered_labels).item()\n",
    "        recall_micro = recall_micro(filtered_preds, filtered_labels).item()\n",
    "        f1_macro = f1_macro(filtered_preds, filtered_labels).item()\n",
    "        f1_micro = f1_micro(filtered_preds, filtered_labels).item()\n",
    "        \n",
    "        coverage = mask.sum().item() / len(all_labels)\n",
    "        \n",
    "        results.append({\n",
    "            'threshold': threshold,\n",
    "            'accuracy': accuracy,\n",
    "            'precision_macro': precision_macro,\n",
    "            'precision_micro': precision_micro,\n",
    "            'recall_macro': recall_macro,\n",
    "            'recall_micro': recall_micro,\n",
    "            'f1_macro': f1_macro,\n",
    "            'f1_micro': f1_micro,\n",
    "            'coverage': coverage,\n",
    "            'num_predictions': mask.sum().item()\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n",
    "def evaluate_topk_accuracy(model, dataloader, num_classes, k_values=[1, 3, 5], custom_classes = None, device='cuda'):\n",
    "    \"\"\"\n",
    "    Evaluate top-k accuracy for different k values\n",
    "    \n",
    "    Args:\n",
    "        model: PyTorch model\n",
    "        dataloader: DataLoader for evaluation\n",
    "        num_classes: Number of classes\n",
    "        k_values: List of k values for top-k accuracy (e.g., [1, 3, 5])\n",
    "        device: Device to run evaluation on\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with top-k accuracy results\n",
    "    \"\"\"\n",
    "\n",
    "    if custom_classes is None:\n",
    "        custom_classes = [i for i in range(num_classes)]\n",
    "    model.eval()\n",
    "    \n",
    "    # Collect all predictions first\n",
    "    all_probs = []\n",
    "    all_labels = []\n",
    "    \n",
    "    print(\"Collecting predictions for top-k evaluation...\")\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
    "            images = images.to(device)\n",
    "            logits = model(images)[:, custom_classes]\n",
    "            probs = torch.softmax(logits, dim=1)\n",
    "            \n",
    "            all_probs.append(probs.cpu())\n",
    "            all_labels.append(labels)\n",
    "    \n",
    "    all_probs = torch.cat(all_probs, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    \n",
    "    results = []\n",
    "    max_k = max(k_values)\n",
    "    \n",
    "    # Get top-k predictions (indices)\n",
    "    _, top_k_indices = torch.topk(all_probs, k=min(max_k, num_classes), dim=1)\n",
    "    \n",
    "    print(\"\\nComputing top-k accuracy...\")\n",
    "    for k in tqdm(k_values, desc=\"Top-K values\"):\n",
    "        if k > num_classes:\n",
    "            print(f\"Warning: k={k} is larger than num_classes={num_classes}, skipping\")\n",
    "            continue\n",
    "        \n",
    "        # Check if true label is in top-k predictions\n",
    "        top_k_preds = top_k_indices[:, :k]\n",
    "        correct = torch.any(top_k_preds == all_labels.unsqueeze(1), dim=1)\n",
    "        \n",
    "        accuracy = correct.float().mean().item()\n",
    "        num_correct = correct.sum().item()\n",
    "        total = len(all_labels)\n",
    "        \n",
    "        # Also compute average confidence for top-k predictions\n",
    "        top_k_probs = torch.gather(all_probs, 1, top_k_preds)\n",
    "        avg_confidence = top_k_probs.mean().item()\n",
    "        \n",
    "        results.append({\n",
    "            'k': k,\n",
    "            'top_k_accuracy': accuracy,\n",
    "            'num_correct': num_correct,\n",
    "            'total_samples': total,\n",
    "            'avg_top_k_confidence': avg_confidence\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c39b9554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded resnet18 weights\n",
      "Collecting predictions for top-k evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 18/46 [02:10<03:50,  8.23s/it]c:\\Users\\rohan\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\PIL\\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing top-k accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Top-K values: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 373.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded resnet50 weights\n",
      "Collecting predictions for top-k evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing top-k accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Top-K values: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded densenet weights\n",
      "Collecting predictions for top-k evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Computing top-k accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Top-K values: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00, 2829.53it/s]\n"
     ]
    }
   ],
   "source": [
    "for model in ['resnet18', 'resnet50', 'densenet']:\n",
    "    result_df = evaluate_topk_accuracy(loadModel(model).to(device), custom_loader, 365, k_values=[1, 3, 5], custom_classes = None, device='cuda')\n",
    "    result_df.to_csv(f'custom_{model}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c15584a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded resnet18 weights\n",
      "Successfully loaded resnet50 weights\n",
      "Successfully loaded densenet weights\n",
      "Using 500 samples from dataset for faster benchmarking\n",
      "\n",
      "================================================================================\n",
      "Benchmarking: ResNet18\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet18 batch sizes:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 3/5 [01:52<01:26, 43.30s/it]c:\\Users\\rohan\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\PIL\\Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "ResNet18 batch sizes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [06:40<00:00, 80.19s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Benchmarking: ResNet50\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet50 batch sizes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [07:36<00:00, 91.35s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "Benchmarking: DenseNet161\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DenseNet161 batch sizes: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [08:37<00:00, 103.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Results saved to: ./benchmark_results\\benchmark_batch_sizes_cpu.csv\n",
      "ðŸ“Š Plots saved to: ./benchmark_results\\benchmark_plots_cpu.png\n",
      "ðŸ“‹ Comparison table saved to: ./benchmark_results\\comparison_table_cpu.png\n",
      "Using 500 samples from dataset for faster benchmarking\n",
      "\n",
      "================================================================================\n",
      "Benchmarking: ResNet18\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResNet18 batch sizes:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 3/6 [02:29<02:29, 49.83s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 364\u001b[39m\n\u001b[32m    362\u001b[39m \u001b[38;5;66;03m# GPU benchmark (if available)\u001b[39;00m\n\u001b[32m    363\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.cuda.is_available():\n\u001b[32m--> \u001b[39m\u001b[32m364\u001b[39m     results_gpu = \u001b[43mbenchmark_batch_sizes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    365\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodels_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodels_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcustom_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_sizes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m16\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m64\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Can test larger batches on GPU\u001b[39;49;00m\n\u001b[32m    368\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcuda\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_iterations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarmup\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_subset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./benchmark_results\u001b[39;49m\u001b[33;43m'\u001b[39;49m\n\u001b[32m    373\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    374\u001b[39m     \u001b[38;5;28mprint\u001b[39m(results_gpu)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 114\u001b[39m, in \u001b[36mbenchmark_batch_sizes\u001b[39m\u001b[34m(models_dict, dataset, batch_sizes, device, num_iterations, warmup, save_dir, sample_subset)\u001b[39m\n\u001b[32m    112\u001b[39m     _ = model(images)\n\u001b[32m    113\u001b[39m     end.record()\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     batch_time_ms = start.elapsed_time(end)\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\rohan\\anaconda3\\envs\\pytorch_env\\Lib\\site-packages\\torch\\cuda\\__init__.py:954\u001b[39m, in \u001b[36msynchronize\u001b[39m\u001b[34m(device)\u001b[39m\n\u001b[32m    952\u001b[39m _lazy_init()\n\u001b[32m    953\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.cuda.device(device):\n\u001b[32m--> \u001b[39m\u001b[32m954\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_synchronize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "import psutil\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gc\n",
    "\n",
    "\n",
    "def benchmark_batch_sizes(models_dict, dataset, batch_sizes=None, device='cpu', \n",
    "                          num_iterations=30, warmup=3, save_dir='./benchmark_results',\n",
    "                          sample_subset=None):\n",
    "    \"\"\"\n",
    "    Optimized benchmark for multiple models across different batch sizes\n",
    "    \n",
    "    Args:\n",
    "        models_dict: Dictionary of {model_name: model}\n",
    "        dataset: PyTorch Dataset to use for benchmarking\n",
    "        batch_sizes: List of batch sizes to test (default: [1, 4, 8, 16, 32])\n",
    "        device: 'cpu' or 'cuda'\n",
    "        num_iterations: Number of batches to process (default: 30)\n",
    "        warmup: Number of warmup iterations (default: 3)\n",
    "        save_dir: Directory to save results\n",
    "        sample_subset: If set, use only this many samples from dataset (speeds up testing)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with all benchmark results\n",
    "    \"\"\"\n",
    "    if batch_sizes is None:\n",
    "        batch_sizes = [1, 4, 8, 16, 32]  # Reduced default batch sizes\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # Use subset of dataset if specified\n",
    "    if sample_subset and len(dataset) > sample_subset:\n",
    "        dataset = torch.utils.data.Subset(dataset, range(sample_subset))\n",
    "        print(f\"Using {sample_subset} samples from dataset for faster benchmarking\")\n",
    "    \n",
    "    process = psutil.Process(os.getpid())\n",
    "    all_results = []\n",
    "    \n",
    "    for model_name, model in models_dict.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"Benchmarking: {model_name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        model = model.to(device)\n",
    "        model.eval()\n",
    "        \n",
    "        # Get model size info (computed once per model)\n",
    "        param_size = sum(p.numel() * p.element_size() for p in model.parameters())\n",
    "        buffer_size = sum(b.numel() * b.element_size() for b in model.buffers())\n",
    "        model_size_mb = (param_size + buffer_size) / 1024 / 1024\n",
    "        num_params = sum(p.numel() for p in model.parameters())\n",
    "        \n",
    "        for batch_size in tqdm(batch_sizes, desc=f\"{model_name} batch sizes\"):\n",
    "            # Create dataloader for this batch size\n",
    "            dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False,  # shuffle=False for consistency\n",
    "                                   num_workers=0, pin_memory=(device=='cuda'), \n",
    "                                   drop_last=True)  # drop_last ensures consistent batch sizes\n",
    "            \n",
    "            # Get baseline memory\n",
    "            if device == 'cpu':\n",
    "                gc.collect()  # Clean memory before measuring\n",
    "                baseline_memory = process.memory_info().rss / 1024 / 1024  # MB\n",
    "            \n",
    "            # Warmup phase (reduced iterations)\n",
    "            dataloader_iter = iter(dataloader)\n",
    "            with torch.no_grad():\n",
    "                for _ in range(min(warmup, len(dataloader))):\n",
    "                    try:\n",
    "                        images, _ = next(dataloader_iter)\n",
    "                        images = images.to(device, non_blocking=True)\n",
    "                        _ = model(images)\n",
    "                        if device == 'cuda':\n",
    "                            torch.cuda.synchronize()\n",
    "                    except StopIteration:\n",
    "                        break\n",
    "            \n",
    "            # Clear cache after warmup\n",
    "            if device == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # Benchmark phase\n",
    "            times = []\n",
    "            cpu_usages = []\n",
    "            memory_usages = []\n",
    "            \n",
    "            dataloader_iter = iter(dataloader)\n",
    "            actual_iterations = min(num_iterations, len(dataloader))\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                for i in range(actual_iterations):\n",
    "                    try:\n",
    "                        images, _ = next(dataloader_iter)\n",
    "                    except StopIteration:\n",
    "                        break\n",
    "                    \n",
    "                    actual_batch_size = images.size(0)\n",
    "                    images = images.to(device, non_blocking=True)\n",
    "                    \n",
    "                    # Measure inference time\n",
    "                    if device == 'cuda':\n",
    "                        torch.cuda.synchronize()\n",
    "                        start = torch.cuda.Event(enable_timing=True)\n",
    "                        end = torch.cuda.Event(enable_timing=True)\n",
    "                        start.record()\n",
    "                        _ = model(images)\n",
    "                        end.record()\n",
    "                        torch.cuda.synchronize()\n",
    "                        batch_time_ms = start.elapsed_time(end)\n",
    "                    else:\n",
    "                        start = time.perf_counter()\n",
    "                        _ = model(images)\n",
    "                        end = time.perf_counter()\n",
    "                        batch_time_ms = (end - start) * 1000\n",
    "                    \n",
    "                    per_image_time_ms = batch_time_ms / actual_batch_size\n",
    "                    times.append(per_image_time_ms)\n",
    "                    \n",
    "                    # Measure CPU and memory (only on CPU, and sample every 5th iteration)\n",
    "                    if device == 'cpu' and i % 5 == 0:\n",
    "                        cpu_usages.append(process.cpu_percent(interval=None))\n",
    "                        memory_usages.append(process.memory_info().rss / 1024 / 1024)\n",
    "            \n",
    "            # Clear cache after benchmark\n",
    "            if device == 'cuda':\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "            # Compute statistics using percentiles for robustness\n",
    "            times_array = np.array(times)\n",
    "            result = {\n",
    "                'model': model_name,\n",
    "                'batch_size': batch_size,\n",
    "                'device': device,\n",
    "                'model_size_mb': model_size_mb,\n",
    "                'num_parameters_millions': num_params / 1e6,\n",
    "                'iterations_completed': len(times),\n",
    "                \n",
    "                # Time metrics (using percentiles to filter outliers)\n",
    "                'mean_time_per_image_ms': np.mean(times_array),\n",
    "                'std_time_per_image_ms': np.std(times_array),\n",
    "                'min_time_per_image_ms': np.percentile(times_array, 5),  # 5th percentile\n",
    "                'max_time_per_image_ms': np.percentile(times_array, 95),  # 95th percentile\n",
    "                'median_time_per_image_ms': np.median(times_array),\n",
    "                \n",
    "                # Throughput\n",
    "                'throughput_images_per_sec': 1000.0 / np.mean(times_array),\n",
    "                'batch_throughput_batches_per_sec': 1000.0 / (np.mean(times_array) * batch_size),\n",
    "            }\n",
    "            \n",
    "            # Add CPU/memory metrics for CPU device\n",
    "            if device == 'cpu' and cpu_usages:\n",
    "                result.update({\n",
    "                    'mean_cpu_percent': np.mean(cpu_usages),\n",
    "                    'max_cpu_percent': np.max(cpu_usages),\n",
    "                    'mean_memory_mb': np.mean(memory_usages) if memory_usages else 0,\n",
    "                    'max_memory_mb': np.max(memory_usages) if memory_usages else 0,\n",
    "                    'memory_increase_mb': (np.mean(memory_usages) - baseline_memory) if memory_usages else 0,\n",
    "                })\n",
    "            \n",
    "            all_results.append(result)\n",
    "        \n",
    "        # Clean up after each model\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "    \n",
    "    # Create DataFrame\n",
    "    results_df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Save results\n",
    "    csv_path = os.path.join(save_dir, f'benchmark_batch_sizes_{device}.csv')\n",
    "    results_df.to_csv(csv_path, index=False)\n",
    "    print(f\"\\nâœ… Results saved to: {csv_path}\")\n",
    "    \n",
    "    # Generate plots\n",
    "    plot_benchmark_results(results_df, save_dir, device)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "\n",
    "def plot_benchmark_results(results_df, save_dir, device):\n",
    "    \"\"\"\n",
    "    Create optimized visualization plots for benchmark results\n",
    "    \"\"\"\n",
    "    models = results_df['model'].unique()\n",
    "    \n",
    "    # Set style\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.rcParams['figure.dpi'] = 100  # Reduced DPI for faster rendering\n",
    "    \n",
    "    # Create figure with subplots\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    fig.suptitle(f'Model Benchmark Comparison ({device.upper()})', fontsize=16, y=0.995)\n",
    "    \n",
    "    # Plot 1: Time per image vs batch size\n",
    "    ax = axes[0, 0]\n",
    "    for model in models:\n",
    "        model_data = results_df[results_df['model'] == model]\n",
    "        ax.plot(model_data['batch_size'], model_data['mean_time_per_image_ms'], \n",
    "               marker='o', label=model, linewidth=2, markersize=6)\n",
    "    ax.set_xlabel('Batch Size', fontsize=11)\n",
    "    ax.set_ylabel('Time per Image (ms)', fontsize=11)\n",
    "    ax.set_title('Inference Time vs Batch Size', fontsize=12)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xscale('log', base=2)\n",
    "    \n",
    "    # Plot 2: Throughput vs batch size\n",
    "    ax = axes[0, 1]\n",
    "    for model in models:\n",
    "        model_data = results_df[results_df['model'] == model]\n",
    "        ax.plot(model_data['batch_size'], model_data['throughput_images_per_sec'], \n",
    "               marker='s', label=model, linewidth=2, markersize=6)\n",
    "    ax.set_xlabel('Batch Size', fontsize=11)\n",
    "    ax.set_ylabel('Throughput (images/sec)', fontsize=11)\n",
    "    ax.set_title('Throughput vs Batch Size', fontsize=12)\n",
    "    ax.legend(fontsize=9)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_xscale('log', base=2)\n",
    "    \n",
    "    # Plot 3: CPU usage (if available)\n",
    "    ax = axes[1, 0]\n",
    "    if 'mean_cpu_percent' in results_df.columns:\n",
    "        for model in models:\n",
    "            model_data = results_df[results_df['model'] == model]\n",
    "            ax.plot(model_data['batch_size'], model_data['mean_cpu_percent'], \n",
    "                   marker='^', label=model, linewidth=2, markersize=6)\n",
    "        ax.set_xlabel('Batch Size', fontsize=11)\n",
    "        ax.set_ylabel('CPU Usage (%)', fontsize=11)\n",
    "        ax.set_title('CPU Usage vs Batch Size', fontsize=12)\n",
    "        ax.legend(fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xscale('log', base=2)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'CPU metrics not available\\n(GPU mode)', \n",
    "               ha='center', va='center', fontsize=11)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    # Plot 4: Memory usage (if available)\n",
    "    ax = axes[1, 1]\n",
    "    if 'mean_memory_mb' in results_df.columns:\n",
    "        for model in models:\n",
    "            model_data = results_df[results_df['model'] == model]\n",
    "            ax.plot(model_data['batch_size'], model_data['mean_memory_mb'], \n",
    "                   marker='d', label=model, linewidth=2, markersize=6)\n",
    "        ax.set_xlabel('Batch Size', fontsize=11)\n",
    "        ax.set_ylabel('Memory Usage (MB)', fontsize=11)\n",
    "        ax.set_title('Memory Usage vs Batch Size', fontsize=12)\n",
    "        ax.legend(fontsize=9)\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.set_xscale('log', base=2)\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, 'Memory metrics not available\\n(GPU mode)', \n",
    "               ha='center', va='center', fontsize=11)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plot_path = os.path.join(save_dir, f'benchmark_plots_{device}.png')\n",
    "    plt.savefig(plot_path, dpi=150, bbox_inches='tight')  # Reduced DPI\n",
    "    print(f\"ðŸ“Š Plots saved to: {plot_path}\")\n",
    "    plt.close()\n",
    "    \n",
    "    # Create comparison table plot\n",
    "    create_comparison_table(results_df, save_dir, device)\n",
    "\n",
    "\n",
    "def create_comparison_table(results_df, save_dir, device):\n",
    "    \"\"\"\n",
    "    Create a summary comparison table\n",
    "    \"\"\"\n",
    "    # Get data for batch_size=1 (single image inference)\n",
    "    single_image_df = results_df[results_df['batch_size'] == 1].copy()\n",
    "    \n",
    "    if len(single_image_df) == 0:\n",
    "        # Use smallest batch size available\n",
    "        min_batch = results_df['batch_size'].min()\n",
    "        single_image_df = results_df[results_df['batch_size'] == min_batch].copy()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 3 + len(single_image_df) * 0.4))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Prepare table data\n",
    "    table_data = []\n",
    "    headers = ['Model', 'Size (MB)', 'Params (M)', 'Time (ms)', 'FPS', 'Throughput (img/s)']\n",
    "    \n",
    "    if 'mean_cpu_percent' in single_image_df.columns:\n",
    "        headers.extend(['CPU (%)', 'RAM (MB)'])\n",
    "    \n",
    "    for _, row in single_image_df.iterrows():\n",
    "        row_data = [\n",
    "            row['model'],\n",
    "            f\"{row['model_size_mb']:.1f}\",\n",
    "            f\"{row['num_parameters_millions']:.2f}\",\n",
    "            f\"{row['mean_time_per_image_ms']:.2f} Â± {row['std_time_per_image_ms']:.2f}\",\n",
    "            f\"{1000/row['mean_time_per_image_ms']:.1f}\",\n",
    "            f\"{row['throughput_images_per_sec']:.1f}\"\n",
    "        ]\n",
    "        \n",
    "        if 'mean_cpu_percent' in row:\n",
    "            row_data.extend([\n",
    "                f\"{row['mean_cpu_percent']:.1f}\",\n",
    "                f\"{row['mean_memory_mb']:.1f}\"\n",
    "            ])\n",
    "        \n",
    "        table_data.append(row_data)\n",
    "    \n",
    "    table = ax.table(cellText=table_data, colLabels=headers, \n",
    "                    loc='center', cellLoc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1, 1.8)\n",
    "    \n",
    "    # Style header\n",
    "    for i in range(len(headers)):\n",
    "        table[(0, i)].set_facecolor('#4472C4')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    # Alternate row colors\n",
    "    for i in range(1, len(table_data) + 1):\n",
    "        for j in range(len(headers)):\n",
    "            if i % 2 == 0:\n",
    "                table[(i, j)].set_facecolor('#E7E6E6')\n",
    "    \n",
    "    batch_label = single_image_df['batch_size'].iloc[0]\n",
    "    plt.title(f'Model Comparison Summary (Batch Size={batch_label}, {device.upper()})', \n",
    "             fontsize=13, weight='bold', pad=15)\n",
    "    \n",
    "    table_path = os.path.join(save_dir, f'comparison_table_{device}.png')\n",
    "    plt.savefig(table_path, dpi=150, bbox_inches='tight')  # Reduced DPI\n",
    "    print(f\"ðŸ“‹ Comparison table saved to: {table_path}\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Optimized usage example\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage with optimizations:\n",
    "    models_dict = {\n",
    "        'ResNet18': loadModel('resnet18', num_classes=365),\n",
    "        'ResNet50': loadModel('resnet50', num_classes=365),\n",
    "        'DenseNet161': loadModel('densenet', num_classes=365),\n",
    "    }\n",
    "    \n",
    "    # CPU benchmark (optimized)\n",
    "    results_cpu = benchmark_batch_sizes(\n",
    "        models_dict=models_dict,\n",
    "        dataset=custom_dataset,\n",
    "        batch_sizes=[1, 4, 8, 16, 32],  # Reduced batch sizes\n",
    "        device='cpu',\n",
    "        num_iterations=30,  # 30 iterations as requested\n",
    "        warmup=3,  # Reduced warmup\n",
    "        sample_subset=500,  # Use only 500 samples for faster testing\n",
    "        save_dir='./benchmark_results'\n",
    "    )\n",
    "    \n",
    "    # GPU benchmark (if available)\n",
    "    if torch.cuda.is_available():\n",
    "        results_gpu = benchmark_batch_sizes(\n",
    "            models_dict=models_dict,\n",
    "            dataset=custom_dataset,\n",
    "            batch_sizes=[1, 4, 8, 16, 32, 64],  # Can test larger batches on GPU\n",
    "            device='cuda',\n",
    "            num_iterations=30,\n",
    "            warmup=3,\n",
    "            sample_subset=500,\n",
    "            save_dir='./benchmark_results'\n",
    "        )\n",
    "        print(results_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9375f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(custom_dataset.class_to_idx)\n",
    "custom_targets = [cat_2_idx[key] for key in custom_dataset.class_to_idx]\n",
    "print([(cat_2_idx[key], custom_dataset.class_to_idx[key]) for key in custom_dataset.class_to_idx])\n",
    "check_point_paths = [f'./finetuned_models/resnet50_20251209_111405/best_loss_model_{i+1}.pth' for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4e7d109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33, 221, 46, 41, 99, 88, 166, 208, 198, 55, 58, 45, 80, 107]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp_dataset = datasets.ImageFolder(\n",
    "    root='./train',\n",
    "    transform=img_transform\n",
    ")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "class_counts = Counter(temp_dataset.targets)\n",
    "\n",
    "# Get class names in the same order as labels\n",
    "class_names = [cls for cls, _ in sorted(new_map.items(), key=lambda x: x[1])]\n",
    "\n",
    "# Sort counts according to class indices\n",
    "counts = [class_counts[i] for i in range(len(class_names))]\n",
    "print(counts)\n",
    "# Plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(class_names, counts, color='skyblue')\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.title(\"Data distribution over classes\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59225ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = ['resnet18', 'resnet50', 'densenet']\n",
    "\n",
    "for check_point_path in model_names[1:2]:\n",
    "    model = loadModel(check_point_path).to(device)\n",
    "    result_df = evaluate_topk_accuracy(model, custom_loader, 365)\n",
    "    print(result_df.top_k_accuracy)\n",
    "    result_df.to_csv(f'{check_point_path}_topk_custom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eb41ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, check_point_path in enumerate(check_point_paths):\n",
    "    model, _ = load_finetuned_model(checkpoint_path=check_point_path, device=device)\n",
    "    result_df = evaluate_topk_accuracy(model, custom_loader, 365)\n",
    "    print(result_df.top_k_accuracy)\n",
    "    result_df.to_csv(f'best_model_{i+1}_topk_custom.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b280df48",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, check_point_path in enumerate(check_point_paths[:3]):\n",
    "    model, _ = load_finetuned_model(checkpoint_path=check_point_path, device=device)\n",
    "    result_df = evaluate_topk_accuracy(model, places_loader, 365)\n",
    "    result_df.to_csv(f'best_model_{i+1}_topk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_counts = Counter(custom_dataset.targets)\n",
    "\n",
    "# Get class names in the same order as labels\n",
    "class_names = [cls for cls, _ in sorted(new_map.items(), key=lambda x: x[1])]\n",
    "\n",
    "# Sort counts according to class indices\n",
    "counts = [class_counts[i] for i in range(len(class_names))]\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.bar(class_names, counts, color='skyblue')\n",
    "plt.xlabel(\"Classes\")\n",
    "plt.ylabel(\"Number of samples\")\n",
    "plt.title(\"Data distribution over classes\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5578c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_images_in_subfolders('./train', dry_run=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1932f9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./val_256/places365_val.txt', 'r') as f:\n",
    "    img_paths = ['./val/' + line.strip().split()[0] for line in f]\n",
    "    print(img_paths[0])\n",
    "len(img_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c27d948",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1, 2], [2, 3], [4, 5]]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
